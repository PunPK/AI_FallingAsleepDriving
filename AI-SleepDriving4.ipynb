{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face_de\n",
    "import face_recognition\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "#Fast Ai\n",
    "from fastbook import *\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score\n",
    "import pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "eye_cascade = cv2.CascadeClassifier(\"eye_de_mo\\haarcascade_eye_tree_eyeglasses.xml\")  \n",
    "#eye_cascade = cv2.CascadeClassifier(\"haarcascade_eye.xml\")  \n",
    "\n",
    "#mouth_cascade = cv2.CascadeClassifier(\"haarcascade_mcs_mouth.xml\")\n",
    "mouth_cascade = cv2.CascadeClassifier(\"haarcascade_smile.xml\")\n",
    "\n",
    "learn_inf_eye = load_learner('eye_data_resnet18_fastai.pkl')\n",
    "\n",
    "learn_inf_yawn = load_learner('yawn_data_resnet18_fastai.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_left_mo(eye_left,roi_color):\n",
    "    for (ex,ey,ew,eh) in eye_left: \n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,127,255),2)\n",
    "        \n",
    "    eye_left_images = []\n",
    "    for (ex, ey, ew, eh) in eye_left:\n",
    "        eye_left_image = roi_color[ey:ey+eh, ex:ex+ew]\n",
    "        eye_left_images.append(eye_left_image)\n",
    "\n",
    "        #   ใช้ eye_left_images ในโมเดลอื่น\n",
    "    for eye_left_image in eye_left_images:\n",
    "        re = learn_inf_eye.predict(eye_left_image)\n",
    "        print(\"Eye left :\",re)\n",
    "\n",
    "def eye_right_mo(eye_right,roi_color):\n",
    "    for (ex,ey,ew,eh) in eye_right: \n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,127,255),2)\n",
    "        \n",
    "    eye_right_images = []\n",
    "    for (ex, ey, ew, eh) in eye_right:\n",
    "        eye_right_image = roi_color[ey:ey+eh, ex:ex+ew]\n",
    "        eye_right_images.append(eye_right_image)\n",
    "\n",
    "    #   ใช้ eye_right_images ในโมเดลอื่น\n",
    "    for eye_right_image in eye_right_images:\n",
    "        re = learn_inf_eye.predict(eye_right_image)\n",
    "        print(\"Eye right :\",re)\n",
    "\n",
    "def eye(roi_gray,roi_color) :\n",
    "    # Detects eyes \n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray, scaleFactor = 1.1, minNeighbors = 10)\n",
    "        #eyes = eye_cascade.detectMultiScale(roi_gray, scaleFactor = 1.1, minNeighbors = 10)\n",
    "    left_eye = None\n",
    "    right_eye = None\n",
    "\n",
    "    for (x, y, w, h) in eyes:\n",
    "        eye_image = roi_gray[y:y+h, x:x+w]\n",
    "    \n",
    "    # แยกดวงตาเป็นตาซ้ายและตาขวาโดยใช้ตำแหน่ง x\n",
    "    if x < roi_gray.shape[1] / 2:  # ตรวจสอบว่าตำแหน่ง x อยู่ด้านซ้ายของภาพ\n",
    "        left_eye = eyes\n",
    "        eye_left_mo(left_eye,roi_color)\n",
    "    elif x > roi_gray.shape[1] / 2:\n",
    "        right_eye = eyes\n",
    "        eye_right_mo(right_eye,roi_color)\n",
    "\n",
    "\n",
    "def mouth(roi_gray,roi_color) :\n",
    "        mouth = mouth_cascade.detectMultiScale(roi_gray, scaleFactor = 2.2, minNeighbors = 30)\n",
    "        #draw a rectangle in mouth\n",
    "        for (mx,my,mw,mh) in mouth: \n",
    "            cv2.rectangle(roi_color,(mx,my),(mx+mw,my+mh),(120,60,222),2) \n",
    "        #new_mouth(roi_color)\n",
    "\n",
    "        mouth_images = []\n",
    "        for (mx,my,mw,mh) in mouth:\n",
    "            mouth_image = roi_color[my:my+mh, mx:mx+mw]\n",
    "            mouth_images.append(mouth_image)\n",
    "\n",
    "        # ใช้ mouth_images ในโมเดลอื่น\n",
    "        for mouth_image in mouth_images:\n",
    "            result_m = learn_inf_yawn.predict(mouth_image)\n",
    "            label_m = result_m[0]\n",
    "            #print(\"Mouth :\",label_m)\n",
    "            #print(f\"Mouth : {label_m}, {result_m[1:3]})\")\n",
    "            print(\"Mouth :\",result_m)\n",
    "\n",
    "def face_MO(frame) :\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    #face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "    #face_landmarks_list = face_recognition.face_landmarks(frame)\n",
    "  \n",
    "    # convert to gray scale of each frames \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # Detects faces of different sizes in the input image \n",
    "    #faces = face_cascade.detectMultiScale(gray, 1.3, 5) \n",
    "    faces2 = face_recognition.face_locations(frame)\n",
    "\n",
    "    for (top, right, bottom, left) in faces2:\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        roi_gray = gray[top:top+bottom, left:left+right] \n",
    "        roi_color = frame[top:top+bottom, left:left+right] \n",
    "\n",
    "        eye(roi_gray,roi_color)\n",
    "        #mouth(roi_gray,roi_color)\n",
    "\n",
    "def mouth_MO2(frame) :  \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    mouth_rects = mouth_cascade.detectMultiScale(gray, scaleFactor = 1.9, minNeighbors = 10)\n",
    "    for (x,y,w,h) in mouth_rects:\n",
    "        y = int(y - 0.15*h)\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "------------start Ai_sleepdiver------------\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'x' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()  \n\u001b[0;32m     21\u001b[0m \u001b[39m# cropped frames from a camera \u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m#frame = cropped_frame(frame)\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m face_MO(frame)\n\u001b[0;32m     24\u001b[0m \u001b[39m#mouth(frame)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39m#mouth_MO2(frame)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39m#re = face_MO(frame)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m#print(re)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[39m# Display\u001b[39;00m\n\u001b[0;32m     30\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mAi_sleepdiver\u001b[39m\u001b[39m'\u001b[39m,frame) \n",
      "Cell \u001b[1;32mIn[3], line 86\u001b[0m, in \u001b[0;36mface_MO\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m     83\u001b[0m roi_gray \u001b[39m=\u001b[39m gray[top:top\u001b[39m+\u001b[39mbottom, left:left\u001b[39m+\u001b[39mright] \n\u001b[0;32m     84\u001b[0m roi_color \u001b[39m=\u001b[39m frame[top:top\u001b[39m+\u001b[39mbottom, left:left\u001b[39m+\u001b[39mright] \n\u001b[1;32m---> 86\u001b[0m eye(roi_gray,roi_color)\n",
      "Cell \u001b[1;32mIn[3], line 40\u001b[0m, in \u001b[0;36meye\u001b[1;34m(roi_gray, roi_color)\u001b[0m\n\u001b[0;32m     37\u001b[0m     eye_image \u001b[39m=\u001b[39m roi_gray[y:y\u001b[39m+\u001b[39mh, x:x\u001b[39m+\u001b[39mw]\n\u001b[0;32m     39\u001b[0m \u001b[39m# แยกดวงตาเป็นตาซ้ายและตาขวาโดยใช้ตำแหน่ง x\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[39mif\u001b[39;00m x \u001b[39m<\u001b[39m roi_gray\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m:  \u001b[39m# ตรวจสอบว่าตำแหน่ง x อยู่ด้านซ้ายของภาพ\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     left_eye \u001b[39m=\u001b[39m eyes\n\u001b[0;32m     42\u001b[0m     eye_left_mo(left_eye,roi_color)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'x' referenced before assignment"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# capture frames from a camera \n",
    "cap = cv2.VideoCapture(2) \n",
    "\n",
    "#Set_FRANE(cap)\n",
    "\n",
    "# ตัวแปรสำหรับคำนวณ FPS\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "\n",
    "#startMo(start_time)\n",
    "\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"------------start Ai_sleepdiver------------\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "# loop \n",
    "while 1:  \n",
    "    # reads frames from a camera \n",
    "    ret, frame = cap.read()  \n",
    "\n",
    "    # cropped frames from a camera \n",
    "    #frame = cropped_frame(frame)\n",
    "    face_MO(frame)\n",
    "    #mouth(frame)\n",
    "    #mouth_MO2(frame)\n",
    "    #re = face_MO(frame)\n",
    "    #print(re)\n",
    "    \n",
    "    # Display\n",
    "    cv2.imshow('Ai_sleepdiver',frame) \n",
    "    frame_count += 1\n",
    "\n",
    "    if time.time() - start_time >= 1:\n",
    "        fps = frame_count / (time.time() - start_time)\n",
    "        print(\"Processing FPS :\", round(fps, 2))\n",
    "        start_time = time.time()\n",
    "        frame_count = 0\n",
    "  \n",
    "    k = cv2.waitKey(5) # Wait Esc to stop  \n",
    "    if k == 27: \n",
    "        print(\"-------------------------------------------\")\n",
    "        print(\"------------close Ai_sleepdiver------------\")\n",
    "        print(\"-------------------------------------------\")\n",
    "        break\n",
    "  \n",
    "# Close the window \n",
    "cap.release() \n",
    "  \n",
    "# De-allocate any associated memory usage \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
